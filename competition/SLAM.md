---
title: Competition
layout: info
Edit: 2019-04-15
toc: false
commentable: false
protected: true
mathjax: true
---

# Lifelong SLAM in the Real Environment
- The task is to evaluate the robustness and accuracy of visual or visual-inertial SLAM algorithms with commodity sensors in dynamic and daily changing environments.

- We intend to provide an advanced benchmark for current and future SLAM research (especially for semantic SLAM) as well as an indicator of their real-world practicality.

- Traditional metrics for SLAM (e.g. ATE, RPE) only measure the accuracy of pose tracking, but for lifelong SLAM the tracking failure rate and re-localization success rate are also important. New metrics shall be designed along with the lifelong learning datasets for SLAM tasks.

# Task-specific Rules
Traditional metrics for SLAM (e.g. ATE, RPE) only measure the accuracy of pose tracking, but for lifelong SLAM the tracking failure rate and re-localization success rate are also important. New metrics shall be designed along with the lifelong learning datasets for SLAM tasks.

# Important Dates
*Dataset Release - June, 2019*
- Choose your favourite subset of sensors (e.g. monocular or depth-only) and develop your SLAM system.
- Evaluate your SLAM with our lifelong robotic vision data.

*First Round - Sept, 2019*
- Register for the competition first. 
- Download datasets, software tools, and upload the results before the deadline.
- Highest-scored teams will be invited to the final round and to the onsite event.

*Final Round - Oct, 2019*
- A new set of data will be used for the final round.
- The algorithms from each team shall be uploaded to our benchmarking server and run in a controlled environment.

*Onsite Event - Nov 6, 2019*
- Results of the final round will be announced.
- Results will be visualized for the audience.

