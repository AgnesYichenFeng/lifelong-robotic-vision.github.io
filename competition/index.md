---
title: Competition
layout: info
Edit: 2019-03-26
toc: false
commentable: false
protected: true
mathjax: true
numbering: false
---

# Lifelong Robotic Vision Competition

The competition is composed of two challenges with separate scoreboards. Each team can register for either challenge or both. The competition will mostly be online, with an on-site workshop at [IROS 2019](https://www.iros2019.org/) to announce the final scores, demonstrate the best results, and hold technical talks and discussions.

> The registration of challenges have been closed, but the workshop will be open to anyone at IROS 2019. For better preparation and communication, We greatly encourage you to [register the workshop](http://openloris.sv.mikecrm.com/1zlaNmJ) (not required though) if you would be likely to join.

## Challenges

For the details of each challenge, please follow their webpages:

> [Lifelong Object Recognition Challenge]({{site.url}}{{site.baseurl}}/competition/Object-Recognition.html) ([leaderboard](https://codalab.lri.fr/competitions/581#results)) (contact: [Qi She](mailto:qi.she@intel.com))

> [Lifelong SLAM Challenge]({{site.url}}{{site.baseurl}}/competition/SLAM.html) ([leaderboard](https://competitions.codalab.org/competitions/21505#results)) (contact: [Xuesong Shi](mailto:xuesong.shi@intel.com))

<details><summary><b>Schedule</b></summary><br>

<i>Dataset Release - July, 2019</i>
<ul>
<li> Register for the competition first.</li>
<li> Download the dataset.</li>
<li> Develop your algorithm, evaluate it with the dataset and improve it.</li>
<li> Benchmarking metrics will be announced.</li>
</ul>

<i>First Round - July to Sept, 2019</i>
<ul>
<li> Download competition datasets, software tools, and upload the model/results before the deadline.</li>
<li> Highest-scored teams will be invited to the final round and to the workshop.</li>
</ul>

<i>Final Round - Oct, 2019</i>
<ul>
<li> A new set of data will be used for the final round.</li>
<li> The algorithms from each team shall be uploaded to our benchmarking server and run in a controlled environment.</li>
</ul>

<i>Workshop - Nov 4, 2019</i>
<ul>
<li> Each team shall deliver a presentation about their techniques, which will be scored by a technical committee and considered in the final ranking.</li>
<li> Final ranks (final round scores & presentation scores) will be announced.</li>
<li> Results will be visualized for the audience.</li>
</ul>

</details>

## Competition Workshop with IROS 2019

Time: Nov 4, 2019

Venue: The Venetian Macao Resort Hotel, Macau, China

The competition workshop will be open to anyone who has registered [IROS 2019](https://iros2019.org/registration).

### Invited Talks

#### From 3D vision to robotics vision

<details><summary><b>Baoquan Chen, Professor, Peking University</b></summary>
<p>
Baoquan Chen is an Endowed Professor of Peking University, where he is the Executive Director of the Center on Frontiers of Computing Studies. His research interests generally lie in computer graphics, visualization, and human-computer interaction. He has published more than 100 papers in international journals and conferences, including 30+ papers in ACM SIGGRAPH (TOG). Chen received an MS in Electronic Engineering from Tsinghua University, Beijing (1994), and a second MS (1997) and then PhD (1999) in Computer Science from the State University of New York at Stony Brook. Chen is the recipient of 2002 Microsoft Innovation Excellence Program, 2003 U.S. NSF CAREER award, 2004 University of Minnesota McKnight Land-Grant Professorship, 2005 IEEE Visualization Best Paper Award, and 2014 Chinagraph Outstanding Achievement Award. Chen serves on the editorial board of ACM Transaction on Graphics, and served as associate editor of IEEE Transaction on Visualization and Computer Graphics, and conference chair of both IEEE Visualization 2005 and SIGGRAPH Asia 2014. Personal web: <a href="https://cfcs.pku.edu.cn/baoquan">cfcs.pku.edu.cn/baoquan</a>
</p>
</details>

In this talk, I will discuss how 3D environment acquisition can benefit from robot platform, and then, how 3D vision becomes an essential part of robotics vision, with 3D visual learning the essential underlying technique.

#### Bespoke machine learning for humanoid robots
<details><summary><b>Giorgio Metta, Scientific Director, Istituto Italiano di Tecnologia - Genoa, Italy</b></summary>
<p>
Giorgio Metta is the Scientific Director of the Istituto Italiano di Tecnologia (IIT) where he coordinated the iCub Project. He holds a MSc cum laude (1994) and PhD (2000) in electronic engineering both from the University of Genoa. From 2001 to 2002 he was postdoctoral associate at the MIT AI-Lab. He was previously with the University of Genoa and since 2012 Professor of Cognitive Robotics at the University of Plymouth (UK). He is member of the board of directors of euRobotics aisbl, the European reference organization for robotics research. Giorgio Metta research activities are in the fields of biologically motivated and humanoid robotics and, in particular, in developing humanoid robots that can adapt and learn from experience. Giorgio Metta is author of more than 250 scientific publications. He has been working as principal investigator and research scientist in about a dozen international as well as national funded projects.
</p>
</details>

We are interested in developing humanoid robots with learning capabilities. Computation and memory  are typically limited on a robot and there are often requirements of tight real-time performance. Therefore we would like to design algorithms with guaranteed computational and memory bounds. We will show that we do not need to sacrifice much in terms of performance (e.g. recognition rates, accuracy, etc.). We will show practical examples in typical robotics applications such as in the estimation of the robotâ€™s dynamics, on the fly object learning, and speech perception. Results come in different flavors as for example in dynamics estimation the controller has to potentially learn and provide estimates in the millisecond range while longer timescales are acceptable in e.g. visual object recognition. Speech recognition, on the other hand, requires integrating voice input over time. We will show implementations in some of our humanoid robots, namely the iCub and the recently developed R1 service robot.

#### Title TBD
<details><summary><b>Jianwei Zhang, Professor, University of Hamburg</b></summary>
<p>
</p>
</details>


### Program: (draft)
<style>
table th:first-of-type {
    width: 30%;
}

table th:nth-of-type(2) {
    width: 30%;
}
</style>

| Time          | Event  | Comments |
|-------------- | ------ | -------- |
| 8:30 - 9:00   | Welcome and overview |  |
| 9:00 - 10:00  | Invited talks |  |
| 10:00 - 10:30 | Coffee break  |  |
| 10:30 - 12:00 | Competition1: Lifelong Object Recognition | Each team gives a short presentation of their techniques |
| 12:00 - 13:30 | Lunch         |  |
| 13:30 - 15:00 | Competition 2: Lifelong SLAM | Each team gives a short presentation of their techniques |
| 15:00 - 15:30 | Coffee break  |  |
| 15:30 - 16:30 | Invited talks |  |
| 16:30 - 17:00 | Awards ceremony | Intel may provide opportunities for further collaborations with the potential teams |
| 17:00 - 18:00 | Discussions   |  |

## Organizers
<img src="https://lifelong-robotic-vision.github.io/about/organizer.png" alt="Human-Robot-Computer" max-width="820" height="auto">

## Partners
We thank the following partners for their data contribution and valuable suggetions on the competition.

<img src="https://lifelong-robotic-vision.github.io/about/partner.png" alt="partner" width="900" height="auto">


